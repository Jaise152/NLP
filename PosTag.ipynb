{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PosTag.ipynb","provenance":[],"authorship_tag":"ABX9TyPr8Qs3nV9uftpxrMdxqpqU"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"47wBQ21vFi8r","executionInfo":{"status":"ok","timestamp":1610111187391,"user_tz":-330,"elapsed":1051,"user":{"displayName":"Jaise Joseph","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7d21TpM-SIbQEn28XDzMSN5c6IYR9Vo1aUAwoMQ=s64","userId":"18363367214747008176"}},"outputId":"9af5cd57-5958-4de2-d9a0-686e0662e82c"},"source":["import nltk \r\n","from nltk.corpus import stopwords \r\n","from nltk.tokenize import word_tokenize, sent_tokenize \r\n","nltk.download('stopwords')\r\n","nltk.download('punkt')\r\n","nltk.download('averaged_perceptron_tagger')"],"execution_count":14,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"xbq3PDbiFmfQ","executionInfo":{"status":"ok","timestamp":1610111189115,"user_tz":-330,"elapsed":1069,"user":{"displayName":"Jaise Joseph","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7d21TpM-SIbQEn28XDzMSN5c6IYR9Vo1aUAwoMQ=s64","userId":"18363367214747008176"}}},"source":["stop_words = set(stopwords.words('english')) \r\n","  \r\n"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"MmuJ9FlsGZMm","executionInfo":{"status":"ok","timestamp":1610111190962,"user_tz":-330,"elapsed":1172,"user":{"displayName":"Jaise Joseph","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7d21TpM-SIbQEn28XDzMSN5c6IYR9Vo1aUAwoMQ=s64","userId":"18363367214747008176"}}},"source":["statement = \"Hello all, I am Dr. Chetana. \" \\\r\n","            \"Welcome to the lab session of Natural Language Processing(NLP). \" \\\r\n","            \"NLP is a very interesting area.\"\r\n","\r\n","# sent_tokenize is one of instances of  \r\n","\r\n","  \r\n"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5xw6QzfxGbaA","executionInfo":{"status":"ok","timestamp":1610111192997,"user_tz":-330,"elapsed":1277,"user":{"displayName":"Jaise Joseph","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7d21TpM-SIbQEn28XDzMSN5c6IYR9Vo1aUAwoMQ=s64","userId":"18363367214747008176"}},"outputId":"f88dc060-af3a-41df-a216-12e244fc1ebd"},"source":["tokenized = sent_tokenize(statement) \r\n","for i in tokenized: \r\n","      \r\n","    # Word tokenizers is used to find the words  \r\n","    # and punctuation in a string \r\n","    wordsList = nltk.word_tokenize(i) \r\n","  \r\n","    # removing stop words from wordList \r\n","    wordsList = [w for w in wordsList if not w in stop_words]  \r\n","  \r\n","    #  Using a Tagger. Which is part-of-speech  \r\n","    # tagger or POS-tagger.  \r\n","    tagged = nltk.pos_tag(wordsList) \r\n","  \r\n","    print(tagged) "],"execution_count":17,"outputs":[{"output_type":"stream","text":["[('Hello', 'NNP'), (',', ','), ('I', 'PRP'), ('Dr.', 'NNP'), ('Chetana', 'NNP'), ('.', '.')]\n","[('Welcome', 'JJ'), ('lab', 'NN'), ('session', 'NN'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('(', '('), ('NLP', 'NNP'), (')', ')'), ('.', '.')]\n","[('NLP', 'NNP'), ('interesting', 'JJ'), ('area', 'NN'), ('.', '.')]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HIuaUGRPGdw6"},"source":[""],"execution_count":null,"outputs":[]}]}